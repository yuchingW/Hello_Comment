{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d00cbda",
   "metadata": {},
   "source": [
    "## BERTpopic\n",
    "\n",
    "- 留言：需要先過濾表情符號、網頁原始碼、ckip斷詞\n",
    "- 逐字稿：清理時間代碼、ckip斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# !pip3.9 install bertopic\n",
    "# !pip3.9 install hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d741d842",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16bdb0b",
   "metadata": {},
   "source": [
    "### 跑留言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a04f797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7q/r8d__s551b5bfd60gl14f1lw0000gn/T/ipykernel_58869/1860163645.py:1: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  comments_df = pd.read_csv('comments/ckip_comments.csv', encoding='utf-8')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_title</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>ws</th>\n",
       "      <th>published_at</th>\n",
       "      <th>author_name</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅</td>\n",
       "      <td>我入鏡了</td>\n",
       "      <td>['我', '入鏡', '了']</td>\n",
       "      <td>2023-10-30T15:40:22Z</td>\n",
       "      <td>@rayduenglish</td>\n",
       "      <td>1142</td>\n",
       "      <td>top_comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅</td>\n",
       "      <td>Ya 果然來留言了</td>\n",
       "      <td>['Ya ', '果然', '來', '留言', '了', ' ']</td>\n",
       "      <td>2023-10-30T15:42:12Z</td>\n",
       "      <td>@TheLian8</td>\n",
       "      <td>15</td>\n",
       "      <td>reply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅</td>\n",
       "      <td>請大笑</td>\n",
       "      <td>['請', '大笑']</td>\n",
       "      <td>2023-10-31T07:05:46Z</td>\n",
       "      <td>@teresayeh3049</td>\n",
       "      <td>18</td>\n",
       "      <td>reply</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     video_title cleaned_text  \\\n",
       "0  【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅         我入鏡了   \n",
       "1  【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅   Ya 果然來留言了    \n",
       "2  【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅          請大笑   \n",
       "\n",
       "                                   ws          published_at     author_name  \\\n",
       "0                    ['我', '入鏡', '了']  2023-10-30T15:40:22Z   @rayduenglish   \n",
       "1  ['Ya ', '果然', '來', '留言', '了', ' ']  2023-10-30T15:42:12Z       @TheLian8   \n",
       "2                         ['請', '大笑']  2023-10-31T07:05:46Z  @teresayeh3049   \n",
       "\n",
       "  like_count comment_type  \n",
       "0       1142  top_comment  \n",
       "1         15        reply  \n",
       "2         18        reply  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ckip data\n",
    "\n",
    "comments_df = pd.read_csv('comments/ckip_comments.csv', encoding='utf-8')\n",
    "data = comments_df[['video_title', 'cleaned_text', 'ws', 'published_at', 'author_name', 'like_count', 'comment_type']]\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22206009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     video_title cleaned_text  \\\n",
      "0  【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅         我入鏡了   \n",
      "1  【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅   Ya 果然來留言了    \n",
      "2  【#賀瓏夜夜秀】10/28 新聞亂報 EP1｜藍白兩情相悅          請大笑   \n",
      "\n",
      "                                   ws          published_at     author_name  \\\n",
      "0                    ['我', '入鏡', '了']  2023-10-30T15:40:22Z   @rayduenglish   \n",
      "1  ['Ya ', '果然', '來', '留言', '了', ' ']  2023-10-30T15:42:12Z       @TheLian8   \n",
      "2                         ['請', '大笑']  2023-10-31T07:05:46Z  @teresayeh3049   \n",
      "\n",
      "  like_count comment_type         ws_clean  \n",
      "0       1142  top_comment           我 入鏡 了  \n",
      "1         15        reply  Ya  果然 來 留言 了    \n",
      "2         18        reply             請 大笑  \n"
     ]
    }
   ],
   "source": [
    "data['ws_clean'] = data[\"ws\"].apply(\n",
    "    lambda x: \" \".join(str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\").split(\", \")) if pd.notnull(x) else \"\"\n",
    ")\n",
    "# print(data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5674559b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153460\n"
     ]
    }
   ],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "\n",
    "vectorizer_model = CountVectorizer(\n",
    "    tokenizer=lambda x: x.split(\" \"),  # 拆空格就好\n",
    ")\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True)\n",
    "representation_model = KeyBERTInspired()\n",
    "hdbscan_model = HDBSCAN(min_cluster_size = 20, metric='euclidean',\n",
    "                        cluster_selection_method='eom', prediction_data=True, min_samples=10)\n",
    "\n",
    "\n",
    "docs = data[\"ws_clean\"].tolist()\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87ea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-12 20:59:48,152 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "Batches: 100%|██████████| 4796/4796 [07:35<00:00, 10.54it/s]\n",
      "\n",
      "2025-05-12 21:08:34,860 - BERTopic - Embedding - Completed ✓\n",
      "2025-05-12 21:08:34,860 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-05-12 21:08:34,860 - BERTopic - Embedding - Completed ✓\n",
      "2025-05-12 21:08:34,860 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-05-12 21:09:56,167 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-05-12 21:09:56,169 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-05-12 21:09:56,167 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-05-12 21:09:56,169 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "topic_model = BERTopic(\n",
    "    language=\"chinese (traditional)\",  # 指定語言為繁體中文\n",
    "    embedding_model=\"distiluse-base-multilingual-cased-v1\",  # 指定用來將文本轉成向量的模型\n",
    "    vectorizer_model=vectorizer_model,  # 指定向量化方法（這裡用你前面自訂的 CountVectorizer）\n",
    "    calculate_probabilities=True,       # 計算每個主題的機率\n",
    "    verbose=True                        # 顯示詳細執行過程\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da2935",
   "metadata": {},
   "source": [
    "### View result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85220825",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2879053",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = topic_model.get_topic_info();\n",
    "freq.head(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_info = topic_model.get_document_info(docs)\n",
    "doc_info.query(\"Topic==1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7ee7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_topics = topic_model.get_topics()\n",
    "df_all_topics = pd.DataFrame(all_topics)\n",
    "df_all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize topics\n",
    "\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics=10, n_words = 10, topics = range(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
