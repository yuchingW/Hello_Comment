{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f5b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have the latest version of the SDK available to use the Batch API\n",
    "# %pip install openai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad47e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ba5e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load openai API key from .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2aaed77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing OpenAI client - see https://platform.openai.com/docs/quickstart?context=python\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce29d2a",
   "metadata": {},
   "source": [
    "# Prepare the data for the batch API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e3568d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "跳過 video_30\n",
      "跳過 video_31\n",
      "跳過 video_32\n"
     ]
    }
   ],
   "source": [
    "# 合併所有的cleaned_text和video_title，準備作為批次上傳的data\n",
    "\"\"\"\n",
    "要分成三批\n",
    "1. v0-v15 跳過10, 11, 12, 16, 17\n",
    "2. v18-v35 跳過v30, 31, 32\n",
    "3. v30-31\n",
    "\"\"\"\n",
    "\n",
    "all_comments = []\n",
    "\n",
    "for i in range(18, 36):\n",
    "    # if i in [10, 11, 12, 16, 17]:\n",
    "    #     print(f\"跳過 video_{i}\")\n",
    "    #     continue\n",
    "\n",
    "    if i in [30, 31, 32]:\n",
    "        print(f\"跳過 video_{i}\")\n",
    "        continue\n",
    "    \n",
    "    file_path = f\"for_gpt_tag/video_{i}_filtered_spam.csv\"\n",
    "    # file_path = f\"spam_tag/comments_spam_tag.csv\"\n",
    "    df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        # print(f\"Processing row {index + 1} of {len(df)}\")\n",
    "        video_title = row['video_title']\n",
    "        cleaned_text = row['cleaned_text']\n",
    "        all_comments.append({\n",
    "            \"video_title\": video_title,\n",
    "            \"comment\": cleaned_text\n",
    "        })\n",
    "\n",
    "# Save the combined data to a JSON file\n",
    "with open('for_gpt_tag/ver2_comments_for_tag.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_comments, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bd5cf640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total comments processed: 44249\n"
     ]
    }
   ],
   "source": [
    "# check length of all_comments\n",
    "print(f\"Total comments processed: {len(all_comments)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb7893",
   "metadata": {},
   "source": [
    "# 從instruction2之後只要讀檔\n",
    "\n",
    "1. for_gpt_tag/ver1_comments_for_tag.json\n",
    "2. for_gpt_tag/ver2_comments_for_tag.json\n",
    "3. for_gpt_tag/ver3_comments_for_tag.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50be9b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46696\n"
     ]
    }
   ],
   "source": [
    "i = 3\n",
    "with open(f'for_gpt_tag/ver{i}_comments_for_tag.json', 'r', encoding='utf-8') as f:\n",
    "    all_comments = json.load(f)\n",
    "\n",
    "print(len(all_comments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "65f37f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up batch input\n",
    "\"\"\"\n",
    "分別上傳instruction1, instruction2, instruction3的batch_input\n",
    "\n",
    "custom_id: instruction\"1\"-task-0, instruction\"2\"-task-1, instruction\"3\"-task-2\n",
    "messages:[\n",
    "{\n",
    "    \"role\": \"system\", \"content\": instruction\"1\"\n",
    "},\n",
    "{\n",
    "    \"role\": \"user\", \"content\": f\"【影片標題】{item['video_title']}\\n【留言內容】{item['comment']}\"\n",
    "}\n",
    "]\n",
    "    \n",
    "\"\"\"\n",
    "from gpt_instructions import *\n",
    "\n",
    "tasks = []\n",
    "\n",
    "for index, item in enumerate(all_comments):\n",
    "    task = {\n",
    "        \"custom_id\": f\"instruction3-task-{index+86284}\", # ver3 : 86284\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4.1-mini\",\n",
    "            \"response_format\": { \n",
    "                \"type\": \"json_object\"\n",
    "            },\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\", \"content\": instruction3\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\", \"content\":\n",
    "                        f\"【影片標題】{item['video_title']}\\n【留言內容】{item['comment']}\"\n",
    "                }\n",
    "            ],\n",
    "            \"temperature\": 0\n",
    "        }\n",
    "    }\n",
    "    tasks.append(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fd12460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the file\n",
    "file_name = \"batch_input/instruction3_ver3_comments.jsonl\"\n",
    "\n",
    "with open(file_name, 'w', encoding='utf-8') as file:\n",
    "    for obj in tasks:\n",
    "        file.write(json.dumps(obj, ensure_ascii=False) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4e149",
   "metadata": {},
   "source": [
    "# 檢查當前所有Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "281de2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[Batch](data=[Batch(id='batch_684bf6bbee048190819505b124197ea4', completion_window='24h', created_at=1749808827, endpoint='/v1/chat/completions', input_file_id='file-3nxJghe61tFku5zu4uYiNm', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749895227, failed_at=None, finalizing_at=None, in_progress_at=1749808849, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=44249)), Batch(id='batch_684bf5a6e3c88190bb3852e848859c35', completion_window='24h', created_at=1749808550, endpoint='/v1/chat/completions', input_file_id='file-4FC84SMm2N6bXJXxDZuwYv', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749894950, failed_at=None, finalizing_at=None, in_progress_at=1749808562, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=42035)), Batch(id='batch_684bf3d489e88190bce5a223854769fe', completion_window='24h', created_at=1749808084, endpoint='/v1/chat/completions', input_file_id='file-NseY25fx744Upm9RzYxNBt', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1749808200, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749894484, failed_at=None, finalizing_at=None, in_progress_at=1749808095, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=220, failed=0, total=46696)), Batch(id='batch_684bf30244cc8190bfce0d1a6783a3ee', completion_window='24h', created_at=1749807874, endpoint='/v1/chat/completions', input_file_id='file-NseY25fx744Upm9RzYxNBt', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1749808410, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749894274, failed_at=None, finalizing_at=None, in_progress_at=1749807884, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=1401, failed=0, total=46696)), Batch(id='batch_684bf015d7388190823e100c889fb8e8', completion_window='24h', created_at=1749807125, endpoint='/v1/chat/completions', input_file_id='file-S9aQx6CZyiD8FJiNyvn2tM', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749893525, failed_at=None, finalizing_at=None, in_progress_at=1749807150, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=3738, failed=0, total=46696)), Batch(id='batch_684bed4d5f70819095f2e5da49f2dd25', completion_window='24h', created_at=1749806413, endpoint='/v1/chat/completions', input_file_id='file-LdtzGWqPvnYgy6MYBn2iAq', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749892813, failed_at=None, finalizing_at=None, in_progress_at=1749806421, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=5743, failed=0, total=44249)), Batch(id='batch_684beb6dbf988190b1a7e5935d00565e', completion_window='24h', created_at=1749805933, endpoint='/v1/chat/completions', input_file_id='file-B7BymxV9asAz7fSAGFL4EH', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='maximum_requests_exceeded', line=None, message='This batch contains more than the 50,000 maximum number of requests. Please try again with a smaller batch.', param=None)], object='list'), expired_at=None, expires_at=1749892333, failed_at=1749805934, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_684beaaf05208190a1f54df6e514a068', completion_window='24h', created_at=1749805743, endpoint='/v1/chat/completions', input_file_id='file-UR7kjVoyhohvdWqEAnG4Dk', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='maximum_requests_exceeded', line=None, message='This batch contains more than the 50,000 maximum number of requests. Please try again with a smaller batch.', param=None)], object='list'), expired_at=None, expires_at=1749892143, failed_at=1749805746, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_684be834800481909e086701c7a3ebab', completion_window='24h', created_at=1749805108, endpoint='/v1/chat/completions', input_file_id='file-FATUM8Pd55BuaDRHKRrV9J', object='batch', status='in_progress', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749891508, failed_at=None, finalizing_at=None, in_progress_at=1749805116, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=8469, failed=0, total=42035)), Batch(id='batch_684be5201b108190941db9ec2e3377d8', completion_window='24h', created_at=1749804320, endpoint='/v1/chat/completions', input_file_id='file-9Sp6EYvkrDyKpe3WRXsnb6', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='maximum_requests_exceeded', line=None, message='This batch contains more than the 50,000 maximum number of requests. Please try again with a smaller batch.', param=None)], object='list'), expired_at=None, expires_at=1749890720, failed_at=1749804322, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0)), Batch(id='batch_684ae93fe98c8190b9da43abc08ca485', completion_window='24h', created_at=1749739839, endpoint='/v1/chat/completions', input_file_id='file-C49vm8dPccpj9hDTep8ai7', object='batch', status='completed', cancelled_at=None, cancelling_at=None, completed_at=1749742196, error_file_id=None, errors=None, expired_at=None, expires_at=1749826239, failed_at=None, finalizing_at=1749741054, in_progress_at=1749739872, metadata=None, output_file_id='file-GtM9TrQt1x2LgpCRa8ymQH', request_counts=BatchRequestCounts(completed=6498, failed=0, total=6498)), Batch(id='batch_684ae557d5cc8190914795a7c9c6a825', completion_window='24h', created_at=1749738839, endpoint='/v1/chat/completions', input_file_id='file-CcRtv9dM9NEzAUAdNSbpAr', object='batch', status='cancelled', cancelled_at=1749740633, cancelling_at=1749739405, completed_at=None, error_file_id='file-3GeGdfFYRgS5hbqUFW2TYh', errors=None, expired_at=None, expires_at=1749825239, failed_at=None, finalizing_at=None, in_progress_at=1749738901, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=3162, total=6498)), Batch(id='batch_684adf116154819097882e423b1f9ee3', completion_window='24h', created_at=1749737233, endpoint='/v1/chat/completions', input_file_id='file-WMsn2oim4nkMHgqroRtose', object='batch', status='failed', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=Errors(data=[BatchError(code='missing_required_parameter', line=1, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=2, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=3, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=4, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=5, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=6, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=7, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=8, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=9, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=10, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=11, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=12, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=13, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=14, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=15, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=16, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=17, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=18, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=19, message=\"Missing required parameter: 'custom_id'.\", param='custom_id'), BatchError(code='missing_required_parameter', line=20, message=\"Missing required parameter: 'custom_id'.\", param='custom_id')], object='list'), expired_at=None, expires_at=1749823633, failed_at=1749737234, finalizing_at=None, in_progress_at=None, metadata={'version': 'test version 20250612', 'video_id': '7, 23, 33'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))], has_more=False, object='list', first_id='batch_684bf6bbee048190819505b124197ea4', last_id='batch_684adf116154819097882e423b1f9ee3')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 檢查所有的batch jobs\n",
    "client.batches.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9227e3",
   "metadata": {},
   "source": [
    "# Upload batch input (jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cd2daa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_file = client.files.create(\n",
    "  file=open(file_name, \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5de73a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-DSJ2HH98pjGk8iKGPaTLZW', bytes=79469205, created_at=1749814865, filename='instruction3_ver3_comments.jsonl', object='file', purpose='batch', status='processed', expires_at=None, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "print(batch_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb50a3d1",
   "metadata": {},
   "source": [
    "# Create Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02459db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.create(\n",
    "  input_file_id=batch_file.id,\n",
    "  endpoint=\"/v1/chat/completions\",\n",
    "  completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada048e",
   "metadata": {},
   "source": [
    "# Check Batch Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e387a761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(id='batch_684c0e972dec819097916ce046138e9f', completion_window='24h', created_at=1749814935, endpoint='/v1/chat/completions', input_file_id='file-DSJ2HH98pjGk8iKGPaTLZW', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749901335, failed_at=None, finalizing_at=None, in_progress_at=None, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "batch = client.batches.retrieve(batch_job.id)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c80a546",
   "metadata": {},
   "source": [
    "### Check Batch Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1cc5832f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id_dict = {\n",
    "    \"instruction1_v1\" : \"batch_684be834800481909e086701c7a3ebab\",\n",
    "    \"instruction1_v2\" : \"batch_684bed4d5f70819095f2e5da49f2dd25\",\n",
    "    \"instruction1_v3\" : \"batch_684bf015d7388190823e100c889fb8e8\",\n",
    "    \"instruction2_v1\" : \"batch_684bf5a6e3c88190bb3852e848859c35\",\n",
    "    \"instruction2_v2\" : \"batch_684bf6bbee048190819505b124197ea4\",\n",
    "    \"instruction2_v3\" : \"batch_684bf76e1a888190b5785faaffda5a0a\",\n",
    "    \"instruction3_v1\" : \"batch_684c0bb660f48190a244b302bc4f82c1\",\n",
    "    \"instruction3_v2\" : \"batch_684c0d89795c8190a8e98210f6ba20a8\",\n",
    "    \"instruction3_v3\" : \"batch_684c0e972dec819097916ce046138e9f\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3b238690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "批次ID: batch_684c0e972dec819097916ce046138e9f\n",
      "批次狀態: completed\n",
      "已完成: 46696\n",
      "失敗: 0\n",
      "總計: 46696\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def check_batch_status(batch_id):\n",
    "    \"\"\"檢查批次處理狀態\"\"\"\n",
    "    batch = client.batches.retrieve(batch_id)\n",
    "    print(f\"批次狀態: {batch.status}\")\n",
    "    print(f\"已完成: {batch.request_counts.completed}\")\n",
    "    print(f\"失敗: {batch.request_counts.failed}\")\n",
    "    print(f\"總計: {batch.request_counts.total}\")\n",
    "    return batch\n",
    "\n",
    "# 定期檢查狀態\n",
    "batch_id = batch_id_dict[\"instruction3_v3\"]\n",
    "\n",
    "# batch_id = batch_job.id\n",
    "print(f\"批次ID: {batch_id}\")\n",
    "\n",
    "current_batch = check_batch_status(batch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17d2a74",
   "metadata": {},
   "source": [
    "# Cancel Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "456ed27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(id='batch_684bf30244cc8190bfce0d1a6783a3ee', completion_window='24h', created_at=1749807874, endpoint='/v1/chat/completions', input_file_id='file-NseY25fx744Upm9RzYxNBt', object='batch', status='cancelling', cancelled_at=None, cancelling_at=1749808410, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1749894274, failed_at=None, finalizing_at=None, in_progress_at=1749807884, metadata=None, output_file_id=None, request_counts=BatchRequestCounts(completed=1401, failed=0, total=46696))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.batches.cancel(\"batch_684bf30244cc8190bfce0d1a6783a3ee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80f4e0",
   "metadata": {},
   "source": [
    "# View ourput result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20caf0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 正在處理檔案: instruction1_ver1_comments.jsonl\n",
      "    處理了 42035 筆資料\n",
      ">>> 正在處理檔案: instruction1_ver2_comments.jsonl\n",
      "    處理了 44249 筆資料\n",
      ">>> 正在處理檔案: instruction1_ver3_comments.jsonl\n",
      "    處理了 46696 筆資料\n",
      "\n",
      "總共處理了 132980 筆資料\n",
      ">>> 資料已保存到 batch_outputs/tag_results.csv\n",
      "\n",
      "=== 前5筆資料預覽 ===\n",
      "  task_id                      video_title                 comment\n",
      "0  task-0  【#賀瓏夜夜秀】1/20 新聞亂報 EP9｜落選夜夜秀謝票大會                  太有活了贵司\n",
      "1  task-1  【#賀瓏夜夜秀】1/20 新聞亂報 EP9｜落選夜夜秀謝票大會       我的天这段影片的评论区是发生了什么\n",
      "2  task-2  【#賀瓏夜夜秀】1/20 新聞亂報 EP9｜落選夜夜秀謝票大會  原来这就是之后节目里提到的被炎上的事件之一吗\n",
      "3  task-3  【#賀瓏夜夜秀】1/20 新聞亂報 EP9｜落選夜夜秀謝票大會        突然發現低卡的夥伴們ᶘ ᵒᴥᵒᶅ\n",
      "4  task-4  【#賀瓏夜夜秀】1/20 新聞亂報 EP9｜落選夜夜秀謝票大會         怎麼選舉可以有這麼多好笑的內容\n"
     ]
    }
   ],
   "source": [
    "# 直接使用 DataFrame 收集資料\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 確保輸出資料夾存在\n",
    "os.makedirs('batch_outputs', exist_ok=True)\n",
    "\n",
    "# 創建空的 DataFrame\n",
    "df_results = pd.DataFrame(columns=['task_id', 'video_title', 'comment'])\n",
    "\n",
    "for vi in range(1, 4):\n",
    "    input_path = f\"batch_input/instruction1_ver{vi}_comments.jsonl\"\n",
    "    \n",
    "    if os.path.exists(input_path):\n",
    "        print(f\">>> 正在處理檔案: instruction1_ver{vi}_comments.jsonl\")\n",
    "        \n",
    "        batch_data = []  # 用來收集當前檔案的資料\n",
    "        \n",
    "        with open(input_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    try:\n",
    "                        data = json.loads(line)\n",
    "                        \n",
    "                        # 1. 提取 task_id (從 custom_id 中提取)\n",
    "                        custom_id = data['custom_id']\n",
    "                        task_id = custom_id.split('-', 1)[1]\n",
    "                        \n",
    "                        # 2. 提取 content\n",
    "                        content = data['body']['messages'][1]['content']\n",
    "                        \n",
    "                        # 3. 使用正則表達式提取 video_title 和 comment\n",
    "                        video_title_match = re.search(r'【影片標題】(.*?)【留言內容】', content, re.DOTALL)\n",
    "                        video_title = video_title_match.group(1).strip() if video_title_match else \"\"\n",
    "                        \n",
    "                        comment_match = re.search(r'【留言內容】(.*)', content, re.DOTALL)\n",
    "                        comment = comment_match.group(1).strip() if comment_match else \"\"\n",
    "                        \n",
    "                        # 加入批次資料\n",
    "                        batch_data.append({\n",
    "                            'task_id': task_id,\n",
    "                            'video_title': video_title,\n",
    "                            'comment': comment\n",
    "                        })\n",
    "                        \n",
    "                    except json.JSONDecodeError as e:\n",
    "                        print(f\"JSON 解析錯誤在檔案 {input_path}: {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"處理錯誤在檔案 {input_path}: {e}\")\n",
    "        \n",
    "        # 將批次資料加入主 DataFrame\n",
    "        if batch_data:\n",
    "            batch_df = pd.DataFrame(batch_data)\n",
    "            df_results = pd.concat([df_results, batch_df], ignore_index=True)\n",
    "            print(f\"    處理了 {len(batch_data)} 筆資料\")\n",
    "    else:\n",
    "        print(f\"檔案不存在: {input_path}\")\n",
    "\n",
    "print(f\"\\n總共處理了 {len(df_results)} 筆資料\")\n",
    "\n",
    "# 保存到 CSV\n",
    "df_results.to_csv('batch_outputs/tag_results.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\">>> 資料已保存到 batch_outputs/tag_results.csv\")\n",
    "\n",
    "# 顯示前幾筆資料\n",
    "print(\"\\n=== 前5筆資料預覽 ===\")\n",
    "print(df_results.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4a5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.read_csv('batch_outputs/tag_results.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3ae3df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始處理批次結果...\n",
      ">>> 處理 instruction1_v1\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      ">>> 完成，共處理 42035 筆\n",
      ">>> 處理 instruction1_v2\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      "    已處理 43000 筆\n",
      "    已處理 44000 筆\n",
      ">>> 完成，共處理 44249 筆\n",
      ">>> 處理 instruction1_v3\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      "    已處理 43000 筆\n",
      "    已處理 44000 筆\n",
      "    已處理 45000 筆\n",
      "    已處理 46000 筆\n",
      ">>> 完成，共處理 46696 筆\n",
      ">>> 處理 instruction2_v1\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      ">>> 完成，共處理 42035 筆\n",
      ">>> 處理 instruction2_v2\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      "    已處理 43000 筆\n",
      "    已處理 44000 筆\n",
      ">>> 完成，共處理 44249 筆\n",
      ">>> 處理 instruction2_v3\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      "    已處理 43000 筆\n",
      "    已處理 44000 筆\n",
      "    已處理 45000 筆\n",
      "    已處理 46000 筆\n",
      ">>> 完成，共處理 46696 筆\n",
      ">>> 處理 instruction3_v1\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      ">>> 完成，共處理 42035 筆\n",
      ">>> 處理 instruction3_v2\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      "    已處理 43000 筆\n",
      "    已處理 44000 筆\n",
      ">>> 完成，共處理 44249 筆\n",
      ">>> 處理 instruction3_v3\n",
      "    已處理 1000 筆\n",
      "    已處理 2000 筆\n",
      "    已處理 3000 筆\n",
      "    已處理 4000 筆\n",
      "    已處理 5000 筆\n",
      "    已處理 6000 筆\n",
      "    已處理 7000 筆\n",
      "    已處理 8000 筆\n",
      "    已處理 9000 筆\n",
      "    已處理 10000 筆\n",
      "    已處理 11000 筆\n",
      "    已處理 12000 筆\n",
      "    已處理 13000 筆\n",
      "    已處理 14000 筆\n",
      "    已處理 15000 筆\n",
      "    已處理 16000 筆\n",
      "    已處理 17000 筆\n",
      "    已處理 18000 筆\n",
      "    已處理 19000 筆\n",
      "    已處理 20000 筆\n",
      "    已處理 21000 筆\n",
      "    已處理 22000 筆\n",
      "    已處理 23000 筆\n",
      "    已處理 24000 筆\n",
      "    已處理 25000 筆\n",
      "    已處理 26000 筆\n",
      "    已處理 27000 筆\n",
      "    已處理 28000 筆\n",
      "    已處理 29000 筆\n",
      "    已處理 30000 筆\n",
      "    已處理 31000 筆\n",
      "    已處理 32000 筆\n",
      "    已處理 33000 筆\n",
      "    已處理 34000 筆\n",
      "    已處理 35000 筆\n",
      "    已處理 36000 筆\n",
      "    已處理 37000 筆\n",
      "    已處理 38000 筆\n",
      "    已處理 39000 筆\n",
      "    已處理 40000 筆\n",
      "    已處理 41000 筆\n",
      "    已處理 42000 筆\n",
      "    已處理 43000 筆\n",
      "    已處理 44000 筆\n",
      "    已處理 45000 筆\n",
      "    已處理 46000 筆\n",
      ">>> 完成，共處理 46696 筆\n",
      "合併資料到 DataFrame...\n",
      "已合併 5000/132980 筆資料\n",
      "已合併 10000/132980 筆資料\n",
      "已合併 15000/132980 筆資料\n",
      "已合併 20000/132980 筆資料\n",
      "已合併 25000/132980 筆資料\n",
      "已合併 30000/132980 筆資料\n",
      "已合併 35000/132980 筆資料\n",
      "已合併 40000/132980 筆資料\n",
      "已合併 45000/132980 筆資料\n",
      "已合併 50000/132980 筆資料\n",
      "已合併 55000/132980 筆資料\n",
      "已合併 60000/132980 筆資料\n",
      "已合併 65000/132980 筆資料\n",
      "已合併 70000/132980 筆資料\n",
      "已合併 75000/132980 筆資料\n",
      "已合併 80000/132980 筆資料\n",
      "已合併 85000/132980 筆資料\n",
      "已合併 90000/132980 筆資料\n",
      "已合併 95000/132980 筆資料\n",
      "已合併 100000/132980 筆資料\n",
      "已合併 105000/132980 筆資料\n",
      "已合併 110000/132980 筆資料\n",
      "已合併 115000/132980 筆資料\n",
      "已合併 120000/132980 筆資料\n",
      "已合併 125000/132980 筆資料\n",
      "已合併 130000/132980 筆資料\n",
      "✅ 完成！\n"
     ]
    }
   ],
   "source": [
    "# 更高效的方法：使用字典收集資料，最後一次性合併\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "# 使用字典來儲存結果，key 是 task_id\n",
    "results_dict = defaultdict(dict)\n",
    "\n",
    "print(\"開始處理批次結果...\")\n",
    "\n",
    "for i in range(1,4):  # instruction1, instruction2, instruction3\n",
    "    for vi in range(1, 4):  # v1, v2, v3\n",
    "        # if i == 3 and vi == 3:\n",
    "        #     continue\n",
    "            \n",
    "        output_path = f\"batch_outputs/instruction{i}_v{vi}_results.jsonl\"\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            print(f\"檔案不存在: {output_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\">>> 處理 instruction{i}_v{vi}\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        with open(output_path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    try:\n",
    "                        data = json.loads(line)\n",
    "                        \n",
    "                        task_id = data['custom_id'].split('-', 1)[1]\n",
    "                        \n",
    "                        # 解析 GPT 回應\n",
    "                        result = data['response']['body']['choices'][0]['message']['content']\n",
    "                        result_json = json.loads(result)\n",
    "                        tag = result_json.get('tag', '')\n",
    "                        reason = result_json.get('reason', '')\n",
    "                        \n",
    "                        # 直接存入字典，避免 DataFrame 查找\n",
    "                        results_dict[task_id][f'tag{i}'] = tag\n",
    "                        results_dict[task_id][f'reason{i}'] = reason\n",
    "                        \n",
    "                        processed_count += 1\n",
    "                        \n",
    "                        # 每 1000 筆顯示進度\n",
    "                        if processed_count % 1000 == 0:\n",
    "                            print(f\"    已處理 {processed_count} 筆\")\n",
    "                            \n",
    "                    except (json.JSONDecodeError, KeyError) as e:\n",
    "                        print(f\"處理錯誤: {e}\")\n",
    "        \n",
    "        print(f\">>> 完成，共處理 {processed_count} 筆\")\n",
    "\n",
    "# 將字典資料合併到原始 DataFrame\n",
    "print(\"合併資料到 DataFrame...\")\n",
    "\n",
    "# 為 df_results 添加新欄位\n",
    "for col in ['tag1', 'reason1', 'tag2', 'reason2', 'tag3', 'reason3']:\n",
    "    if col not in df_results.columns:\n",
    "        df_results[col] = None\n",
    "\n",
    "# 一次性更新所有資料\n",
    "for idx, row in df_results.iterrows():\n",
    "    task_id = row['task_id']\n",
    "    if task_id in results_dict:\n",
    "        for key, value in results_dict[task_id].items():\n",
    "            df_results.at[idx, key] = value\n",
    "    \n",
    "    # 顯示進度\n",
    "    if (idx + 1) % 5000 == 0:\n",
    "        print(f\"已合併 {idx + 1}/{len(df_results)} 筆資料\")\n",
    "\n",
    "# 保存結果\n",
    "df_results.to_csv('batch_outputs/tag_results_combined.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"✅ 完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39e14908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125979"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3564303c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 過濾後剩下：125979\n"
     ]
    }
   ],
   "source": [
    "# 過濾掉len(comments) >128\n",
    "df_filtered = df_results[df_results['comment'].str.len() <= 128]\n",
    "print(f\">>> 過濾後剩下：{len(df_filtered)}\")\n",
    "\n",
    "df_filtered.to_csv('batch_outputs/tag_results_filtered.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0dd219",
   "metadata": {},
   "source": [
    "# 檢查每一部影片中的廢話"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdbbdc4",
   "metadata": {},
   "source": [
    "- if tag1, tag2, ta3 有兩個都是 true ：['spam_tag'] == \"spam\"\n",
    "- else： ['spam_tag'] == \"non_spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df35af9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('batch_outputs/tag_results_filtered.csv', encoding='utf-8-sig')\n",
    "\n",
    "def spam_tag(row):\n",
    "    \"\"\"判斷是否為垃圾留言\"\"\"\n",
    "    spam_count = 0\n",
    "    if row['tag1'] == True:\n",
    "        spam_count += 1\n",
    "    if row['tag2'] == True:\n",
    "        spam_count += 1\n",
    "    if row['tag3'] == True:\n",
    "        spam_count += 1\n",
    "\n",
    "    if spam_count >= 2:\n",
    "        df.at[row.name, 'spam_tag'] = 'spam'\n",
    "    else:\n",
    "        df.at[row.name, 'spam_tag'] = 'non-spam'\n",
    "    return df.at[row.name, 'spam_tag']\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    spam_tag(row)\n",
    "# Save the final DataFrame with spam tags\n",
    "df.to_csv('batch_outputs/tag_results_final.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 描述性統計：spam/non-spam留言的數量和比例\n",
    "\n",
    "spam_df = pd.read_csv('batch_outputs/tag_results_final.csv', encoding='utf-8-sig')\n",
    "\n",
    "usefull_comment_df = spam_df[spam_df['spam_tag'] == 'non-spam']\n",
    "usefull_comment_df.to_csv('batch_outputs/useful_comments.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# count spam and non-spam comments by video title\n",
    "video_spam_stats = spam_df.groupby(['video_title', 'spam_tag']).size().unstack(fill_value=0)\n",
    "video_spam_stats.columns = ['non_spam_count', 'spam_count']\n",
    "\n",
    "video_spam_stats['total_comments'] = video_spam_stats['non_spam_count'] + video_spam_stats['spam_count']\n",
    "video_spam_stats['spam_percentage'] = (video_spam_stats['spam_count'] / video_spam_stats['total_comments'] * 100).round(2)\n",
    "\n",
    "video_spam_stats.reset_index(inplace=True)\n",
    "video_spam_stats_sorted = video_spam_stats.sort_values('spam_percentage', ascending=False)\n",
    "\n",
    "video_spam_stats_sorted.to_csv('batch_outputs/video_spam_statistics.csv', index=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc237a8a",
   "metadata": {},
   "source": [
    "## 人工標註1000則 -> 用傳統機器學習的方法評估準確性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spam跟non-spam各抽500則做人工抽查\n",
    "\n",
    "spam_df = df[df['spam_tag'] == 'spam'].sample(n=500, random_state=42)\n",
    "non_spam_df = df[df['spam_tag'] == 'non-spam'].sample(n=500, random_state=42)\n",
    "final_sample_df = pd.concat([spam_df, non_spam_df], ignore_index=True)\n",
    "\n",
    "# 隨機打亂最終的抽樣結果\n",
    "final_sample_df = final_sample_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "final_sample_df.to_csv('batch_outputs/result_for_check.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f47be3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# human tag data\n",
    "human_tag_df = pd.read_csv(\"batch_outputs/human_tag_result.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# 合併人工標註和LLM標註結果\n",
    "gpt_tag_df = pd.read_csv(\"batch_outputs/tag_results_final.csv\", encoding='utf-8-sig')\n",
    "\n",
    "# 設定 task_id 為 index\n",
    "gpt_tag_df.set_index('task_id', inplace=True)\n",
    "human_tag_df.set_index('task_id', inplace=True)\n",
    "\n",
    "# 只取 human_tag 欄位加入到 gpt_tag_df\n",
    "merged_df = gpt_tag_df.copy()\n",
    "merged_df['human_tag'] = human_tag_df['human_tag']\n",
    "\n",
    "# 如果需要重置 index 回到一般欄位\n",
    "merged_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3050f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.head(5)\n",
    "merged_df.to_csv(\"batch_outputs/merged_tag_results.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab5d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision（精確率）: 0.845\n",
      "Recall（召回率）: 0.8672228585053072\n",
      "F1 Score: 0.8426189825875673\n",
      "Accuracy（準確率）: 0.845\n"
     ]
    }
   ],
   "source": [
    "# 計算標註一致性\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# 範例資料\n",
    "true_labels = human_tag_df['human_tag']\n",
    "pred_labels = human_tag_df['spam_tag']\n",
    "\n",
    "# 計算四個指標（macro平均適用於不平衡資料）\n",
    "precision = precision_score(true_labels, pred_labels, average='macro')\n",
    "recall = recall_score(true_labels, pred_labels, average='macro')\n",
    "f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "print('Precision（精確率）:', precision)\n",
    "print('Recall（召回率）:', recall)\n",
    "print('F1 Score:', f1)\n",
    "print('Accuracy（準確率）:', accuracy)\n",
    "\n",
    "# 儲存結果\n",
    "results = {\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": f1,\n",
    "    \"accuracy\": accuracy\n",
    "}\n",
    "results_df = pd.DataFrame([results])\n",
    "results_df.to_csv(\"batch_outputs/llm_tagging_metrics.csv\", index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
